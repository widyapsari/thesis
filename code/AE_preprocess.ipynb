{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04f2369e-9bd4-4239-b428-19fd18d5a805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Widya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f76e7729-3ed3-4f10-8291-37bf37588256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet): #This cleaning can be improved, check train_asterisk.csv for info\n",
    "    \"\"\"\n",
    "    This function is used to clean the sentence froom column \"tweet\" train and test dataframe\n",
    "    :type tweet: string\n",
    "    \"\"\"\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", '', tweet)\n",
    "    tweet = re.sub(\"#\", \"\", tweet)\n",
    "    # tweet = re.sub(r\"[^a-zA-Z\\s]\", \"\", tweet) #Removes also inner *, but also emoticones\n",
    "    tweet = re.sub(r\"\\s[^a-zA-Z]\\s\", \" \", tweet) #This and 2 lower lines do not remove inner *, but also not emoticones\n",
    "    tweet = re.sub(r\"\\s[^a-zA-Z]\", \" \", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z]\\s\", \" \", tweet)\n",
    "    tweet = tweet.strip('*')\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     stop_words = set(stopwords.words('english'))  \n",
    "#     words = tweet.split()\n",
    "#     words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "#     tweet = ' '.join(words)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ca3f52-526e-4041-b177-ce4e5df31051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset #\n",
    "df_train = pd.read_csv('../dataset/abuseval_train.csv')\n",
    "df_test = pd.read_csv('../dataset/abuseval_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a412ce35-189c-41c6-a628-8c9536f6df4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go home youâ€™re drunk!! maga trump202 ðŸ‡ºðŸ‡¸ url</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone should'vetaken this piece of shit to ...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberals amp illegals to move in...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet   label\n",
       "0   she should ask a few native americans what th...  NOTABU\n",
       "1        go home youâ€™re drunk!! maga trump202 ðŸ‡ºðŸ‡¸ url  NOTABU\n",
       "2  amazon is investigating chinese employees who ...  NOTABU\n",
       "3   someone should'vetaken this piece of shit to ...  NOTABU\n",
       "4   obama wanted liberals amp illegals to move in...  NOTABU"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save training \n",
    "df_train['tweet'] = df_train['tweet'].apply(clean_tweet)\n",
    "df_train = df_train.drop(\"id\", axis=1)\n",
    "df_train.rename(columns={\"abuse\":\"label\"}, inplace=True) \n",
    "df_train.to_csv('../dataset/train.csv', index=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d10ae315-2554-41b7-87f7-27c89943d01b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whoisq wherestheserver dumpnike declasfisa dem...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constitutionday is revered by conservatives ha...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foxnews nra maga potus trump ndamendment rnc u...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watching boomer getting the news that she is s...</td>\n",
       "      <td>NOTABU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nopasaran unity demo to oppose the far-right i...</td>\n",
       "      <td>EXP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet   label\n",
       "0  whoisq wherestheserver dumpnike declasfisa dem...  NOTABU\n",
       "1  constitutionday is revered by conservatives ha...  NOTABU\n",
       "2  foxnews nra maga potus trump ndamendment rnc u...  NOTABU\n",
       "3  watching boomer getting the news that she is s...  NOTABU\n",
       "4  nopasaran unity demo to oppose the far-right i...     EXP"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save test \n",
    "df_test['tweet'] = df_test['tweet'].apply(clean_tweet)\n",
    "df_test = df_test.drop(\"id\", axis=1)\n",
    "df_test.rename(columns={\"abuse\":\"label\"}, inplace=True) \n",
    "df_test.to_csv('../dataset/test.csv', index=False)\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
